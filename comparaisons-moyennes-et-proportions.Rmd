---
title: "Comparaisons (moyennes et proportions)"
---

```{r options_communes, include=FALSE}
source("options_communes.R")
```

Nous utiliserons dans ce chapitre les données de l'enquête *Histoire de vie 2003*
fournies avec l'extension `questionr`{.pkg}.

```{r}
library(questionr)
data("hdv2003")
d <- hdv2003
```

## Comparaison de moyennes{#comp_moyennes}

On peut calculer la <dfn>moyenne</dfn> d'âge des deux groupes en utilisant la
fonction `tapply`{data-pkg="base"}^[La fonction `tapply`{data-pkg="base"} est présentée plus en 
détails dans le chapitre [Manipulation de données](pem_manipulation.html#tapply).] :

```{r}
tapply(d$age, d$hard.rock, mean)
```

L'écart est important. Est-il statistiquement significatif ? Pour cela on peut faire un 
<dfn>test t de Student</dfn><dfn data-index="Student, test t"></dfn>
<dfn>comparaison de moyennes</dfn><dfn data-index="moyenne, comparaison"></dfn>
à l'aide de la fonction `t.test`{data-pkg="stats"} :

```{r}
t.test(d$age ~ d$hard.rock)
```

Le test est extrêmement significatif. L'<dfn>intervalle de confiance</dfn>
à 95 % de la différence entre les deux
moyennes va de 14,5 ans à 21,8 ans.

<div class="note">
La valeur affichée pour *p* est de `1.611e-07`. Cette valeur peut paraître étrange pour les non avertis. Cela
signifie tout simplement 1,611 multiplié par 10 à la puissance -7, autrement dit 0,0000001611. Cette manière
de représenter un nombre est couramment appelée 
<dfn>notation scientifique</dfn><dfn data-index="scientifique, notation"></dfn>. 

Pour plus de détails, voir <http://fr.wikipedia.org/wiki/Notation_scientifique>.
</div>

Nous sommes cependant allés un peu vite en besogne, car nous avons négligé une hypothèse fondamentale
du test *t* : les ensembles de valeur comparés doivent suivre approximativement une 
<dfn>loi normale</dfn><dfn data-index="normale, loi"></dfn>
et être de même <dfn>variance</dfn>^[Concernant cette seconde condition, 
`t.test`{data-pkg="stats"} propose 
une option nommée `var.equal` qui permet d'utiliser une approximation
dans le cas où les variances ne sont pas égales.]. Comment le vérifier ?

D'abord avec un petit graphique composés de deux 
<dfn data-index="histogramme">histogrammes</dfn> :

<figure>
```{r}
par(mfrow = c(1, 2))
hist(d$age[d$hard.rock == "Oui"], main = "Hard rock", col = "red")
hist(d$age[d$hard.rock == "Non"], main = "Sans hard rock", col = "red")
```
<figcaption>Distribution des âges pour appréciation de la normalité</figcaption>
</figure>

<div class="note">
La fonction `par`{data-pkg="graphics"} permet de modifier de nombreux paramètres graphiques.
`par(mfrow = c(1, 2))` sert à indiquer que l'on souhaite afficher deux graphiques sur une même fenêtre,
plus précisément que la fenêtre doit comporter une ligne et deux colonnes.
</div>

Ça a l'air à peu près bon pour les « Sans hard rock », mais un peu plus limite pour les fans de
*Metallica*, dont les effectifs sont d'ailleurs assez faibles. Si on veut en avoir le coeur net 
on peut utiliser le 
<dfn>test de normalité de Shapiro-Wilk</dfn><dfn data-index="normalité, test de Shapiro-Wilk"></dfn><dfn data-index="Shapiro-Wilk, test de normalité"></dfn>
avec la fonction `shapiro.test`{data-pkg="stats"} :

```{r}
shapiro.test(d$age[d$hard.rock == "Oui"])
shapiro.test(d$age[d$hard.rock == "Non"])
```

Visiblement, le test estime que les distributions ne sont pas suffisamment proches de la normalité dans
les deux cas.

Et concernant l'égalité des variances ?

```{r}
tapply(d$age, d$hard.rock, var)
```

L'écart n'a pas l'air négligeable. On peut le vérifier avec le 
<dfn>test d'égalité des variances</dfn><dfn data-index="variance, test d'égalité"></dfn>
fourni par la fonction `var.test`{data-pkg="stats"} :

```{r}
var.test(d$age ~ d$hard.rock)
```

La différence est très significative. En toute rigueur le test *t* n'aurait donc pas pu être utilisé.

*Damned* ! Ces maudits tests statistiques vont-ils nous empêcher de faire connaître au monde entier
notre fabuleuse découverte sur l'âge des fans de *Sepultura* ? Non ! Car voici qu'approche à 
l'horizon un nouveau test, connu sous le nom de 
<dfn data-index="test de Wilcoxon/Mann-Whitney">Wilcoxon/Mann-Whitney</dfn><dfn data-index="Wilcoxon, test"></dfn><dfn data-index="Mann-Whitney, test"></dfn><dfn data-index="médiane, test de comparaison"></dfn><dfn data-index="comparaison de médianes, test"></dfn>. 
Celui-ci a l'avantage d'être non-paramétrique,
c'est à dire de ne faire aucune hypothèse sur la distribution des échantillons comparés. 
Par contre il ne compare pas des différences de moyennes mais des différences de 
<dfn data-index="médiane">médianes</dfn> :

```{r}
wilcox.test(d$age ~ d$hard.rock)
```

Ouf ! La différence est hautement significative^[Ce test peut également fournir un intervalle de confiance 
avec l'option `conf.int=TRUE`.]. Nous allons donc pouvoir entamer la rédaction de
notre article pour la *Revue française de sociologie*.

## Comparaison de proportions{#comp_prop}

La fonction `prop.test`{data-pkg="stats"}, que nous avons déjà rencontrer pour 
calculer l'intervalle de confiance d'une proportion (voir le chapitre dédié aux
[intervalles de confiance](intervalles-de-confiance.html)) permets également d'effectuer
un <dfn>test de comparaison de deux proportions</dfn><dfn data-index="comparaison de proportions, test"></dfn><dfn data-index="proportion, test de comparaison"></dfn>.

Supposons que l'on souhaite comparer la proportion de personnes faisant du sport entre
ceux qui lisent des bandes dessinées et les autres :

```{r}
tab <- xtabs(~ lecture.bd + sport, d)
lprop(tab)
```

Il suffit de transmettre notre tableau croisé (à 2×2 dimensions) à `prop.test`{data-pkg="stats"} :

```{r}
prop.test(tab)
```

On pourra également avoir recours à la fonction `fisher.test`{data-pkg="stats"} qui
renverra notamment l'<dfn>odds ratio</dfn> et son intervalle de confiance correspondant :

```{r}
fisher.test(table(d$lecture.bd, d$sport))
```

On pourra aussi avoir recours à la fonction `odds.ratio`{data-pkg="questionr"} de l'extension
`questionr`{.pkg} qui réalise le même calcul mais présente le
résultat légèrement différemment :

```{r}
odds.ratio(tab)
```


Note : pour le calcul du <dfn>risque relatif</dfn>, on pourra regarder du côté de la fonction
`relrisk`{data-pkg="mosaic"} de l'extension `mosaic`{.pkg}.


## &chi;² et dérivés {#chi2}

Dans le cadre d'un tableau croisée, on peut tester l'existence d'un lien entre les modalités de deux variables, avec le très classique
<dfn data-index="test du Chi²">test du &chi;²</dfn><dfn data-index="Chi², test"></dfn>^[On ne
donnera pas plus d'indications sur le test du &chi;² ici. Les personnes désirant une 
présentation plus détaillée pourront se reporter (attention, séance d'autopromotion !) à la page suivante :
<http://alea.fr.eu.org/pages/khi2>.]. Celui-ci s'obtient grâce à la fonction
`chisq.test`{data-pkg="stats"}, appliquée au tableau croisé obtenu avec `table`{data-pkg="base"} 
ou `xtabs`{data-pacakge="stats"}^[On peut aussi appliquer directement le test 
en spécifiant les deux variables à croiser via `chisq.test(d$qualreg, d$sport)`.] :

```{r}
d$qualreg <- as.character(d$qualif)
d$qualreg[d$qualif %in% c("Ouvrier specialise", "Ouvrier qualifie")] <- "Ouvrier"
d$qualreg[d$qualif %in% c("Profession intermediaire", 
  "Technicien")] <- "Intermediaire"

tab <- table(d$sport, d$qualreg)
tab
chisq.test(tab)
```

Le test est hautement significatif, on ne peut pas considérer qu'il y a indépendance entre les lignes et
les colonnes du tableau.

On peut affiner l'interprétation du test en déterminant dans quelle case l'écart à l'indépendance est
le plus significatif en utilisant les <dfn data-index="résidus, test du Chi²">résidus</dfn><dfn data-index="test du Chi², résidus"></dfn><dfn data-index="Chi², résidus"></dfn>
du test. Ceux-ci sont notamment affichables avec la fonction
`chisq.residuals`{data-pkg="questionr"} de `questionr`{.pkg} :

```{r}
chisq.residuals(tab)
```

Les cases pour lesquelles l'écart à l'indépendance est significatif ont un résidu dont la valeur est
supérieure à 2 ou inférieure à -2. Ici on constate que la pratique d'un sport est sur-représentée parmi
les cadres et, à un niveau un peu moindre, parmi les professions intermédiaires, tandis qu'elle est sousreprésentée
chez les ouvriers.

Enfin, on peut calculer le 
<dfn>coefficient de contingence de Cramer</dfn><dfn data-index="Cramer, coefficient de contingence"></dfn><dfn data-index="tableau croisé, coefficient de contingence de Cramer"></dfn>
du tableau, qui peut nous permettre de le comparer par la suite à d'autres tableaux croisés. 
On peut pour cela utiliser la fonction 
`cramer.v`{data-pkg="questionr"} de `questionr`{.pkg} :

```{r}
cramer.v(tab)
```

<div class="note">
Pour un tableau à 2×2 entrées, il est possible de calculer le 
<dfn>test exact de Fisher</dfn><dfn data-index="Fisher, test exact"></dfn><dfn data-index="tableau croisé, test exact de Fisher"></dfn>
avec la fonction `fisher.test`{data-pkg="stats"}. On peut soit lui passer le résultat 
de `table`{data-pkg="base"} ou `xtabs`{data-pkg="stats"}, 
soit directement les deux variables à croiser.

```{r}
lprop(table(d$sexe, d$cuisine))
fisher.test(table(d$sexe, d$cuisine))
```
</div>

## Données pondérées et l'extension survey{#survey}

Lorsque l'on utilise des données pondérées, on aura recours à l'extension `survey`{.pkg}^[Voir le chapitre dédié aux [données pondérées](donnees-ponderees.html#survey).].

Préparons des données d'exemple :

```{r, message=FALSE}
library(survey)
dw <- svydesign(ids = ~1, data = d, weights = ~poids)
```

Pour comparer deux moyennes à l'aide d'un test *t* on aura recours à `svyttest`{data-pkg="survey"} :

```{r}
svyttest(age~sexe, dw)
```

Pour le test de Wilcoxon/Mann-Whitney, on pourra avoir recours à `svyranktest`{data-pkg="survey"} :


```{r}
svyranktest(age~hard.rock, dw)
```

On ne peut pas utiliser `chisq.test`{data-pkg="stats"} directement sur un tableau généré 
par `svytable`{data-pkg="survey"}. Les effectifs étant extrapolés à partir de la pondération, 
les résultats du test seraient complètement faussés. Si on veut faire
un test du &chi;² sur un tableau croisé pondéré, il faut utiliser 
`svychisq`{data-pkg="survey" data-rdoc="svytable"} :

```{r}
rprop(svytable(~sexe + clso, dw))
svychisq(~sexe + clso, dw)
```

L'extension `survey`{.pkg} ne propose pas de version adaptée du test exact de Fisher. Pour comparer deux proportions, on aura donc recours au test du &chi;² :

```{r}
rprop(svytable(~lecture.bd + sport, dw))
svychisq(~lecture.bd + sport, dw)
```
