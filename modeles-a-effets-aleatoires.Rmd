---
title: "Modèles à effets aléatoires (modèles mixtes et GEE)"
---

```{r options_communes, include=FALSE}
source("options_communes.R")
```

<div class="important">
Ce chapitre est en cours d'écriture.
</div>

<div class="note">
Les exemples de ce chapitre sont repris d'un support de cours de Lionel Riou França disponible en ligne à <http://christophe.genolini.free.fr/recherche/aTelecharger/Multilevel.pdf>.
</div>

<!---

Dans un modèle de régression classique, il s'agit d'étudier la liaison statistique entre une variable à expliquer <var>Y</var> et des variables explicatives <var>X</var> non aléatoire. Soit <var>y~i~</var> la réponse de l'individu <var>i</var> et <var>x~i~</var> les valeurs prises par les variables explicatives pour cet individu. La relation entre <var>X</var> et <var>Y</var> peut s'écrire sous la forme :

$$y_{i}=\alpha +\beta x_{i}+\varepsilon_{i}$$

où $\varepsilon_{i}$ est une variable aléatoire distribuée selon une loi normale d'espérance nulle et représentant les <dfn>résidus du modèle</dfn> ou erreurs, $\alpha$ correspond à ce qu'on appelle l'<dfn>intercept</dfn> et $\beta$ représente les <dfn>coefficients du modèle</dfn>. 

Dans un modèle classique, les erreurs sont supposées être indépendantes et identiquement distribuées selon une loi normale. Or, ce n'est pas le cas dans un certain nombres de cas :

---->




