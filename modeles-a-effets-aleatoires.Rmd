---
title: "Modèles à effets aléatoires (modèles mixtes et GEE)"
---

<!--- Fix #30 -->

```{r options_communes, include=FALSE}
source("options_communes.R")
```

## De la régression linéaire aux modèles mixtes

Dans un modèle de régression classique, il s'agit d'étudier la liaison statistique entre une variable à expliquer <var>Y</var> et des variables explicatives <var>X</var> non aléatoire. Soit <var>y~i~</var> la réponse de l'individu <var>i</var> et <var>x~i~</var> les valeurs prises par les variables explicatives pour cet individu. La relation entre <var>X</var> et <var>Y</var> peut s'écrire sous la forme :

$$y_{i}=\alpha +\beta x_{i}+\varepsilon_{i}$$

où $\varepsilon_{i}$ est une variable aléatoire distribuée selon une loi normale d'espérance nulle et représentant les <dfn>résidus du modèle</dfn> ou erreurs, $\alpha$ correspond à ce qu'on appelle l'<dfn>intercept</dfn> et $\beta$ représente les <dfn>coefficients du modèle</dfn>.

Dans un modèle classique, les erreurs sont supposées être indépendantes et identiquement distribuées selon une loi normale. Or, ce n'est pas le cas dans un certain nombres de cas : lorsque plusieurs réponses sont disponibles pour le même individu pour un même <var>x~i</var> (cas des mesures répétées), lorsque plusieurs observations sont naturellement groupées (p.ex., les membres d'une famille, des jumeaux homozygotes, des patients dans une même unité de soins, etc.), ou lorsque l'on collecte des données au cours du temps chez un même individu.

## Cas des données corrélées discrètes

### Approche GEE

Le cas des données discrètes pose en plus le problème du choix de la distribution pour la variable réponse (ou les erreurs). Une distribution binomiale ou multinomiale convient mieux aux cas où la variable modélisée correspond à un choix binaire ou à plus de deux catégories de réponse. De plus, le choix de la stratégie de modélisation influence également les conclusions que l'on peut tirer d'une étude. Comme on l'a vu plus haut, les modèles linéaires mixtes généralisés permettent d'estimer les paramètres sujet-spécifiques d'un modèle de régression en considérant des effets fixes et/ou aléatoires, éventuellement en considérant différentes structures de corrélation. Une alternative consiste à modéliser directement les effets moyens des facteurs fixes, sans se soucier des effets individuels, en supposant toutefois une matrice de corrélation de travail qui permette de rendre compte de la corrélation intra-unité. Cette approche est connue sous le terme Équations d'estimation généralisées (GEE dans la littérature anglo-saxonne).

En ce qui concerne la matrice de corrélation de travail, voici 4 solutions qui peuvent constituer notre modèle de variance. Le premier cas correspond à une matrice d'indépendance (`ind`), où toutes les observations sont indépendantes les unes des autres :

$$
\begin{pmatrix}
1 & 0 & \cdots & 0 \cr
0 & 1 & \cdots & 0 \cr
\vdots & \vdots & \ddots & \vdots \cr
0 & 0 & \cdots & 1
\end{pmatrix}
$$

On peut également considérer le cas d'une structure de corrélation symétrique ou échangeable (`exch`), telle que celle assumée dans une ANOVA à mesures répétées (cf. hypothèse de symétrie composée, ou sphéricité), où $\rho$ désigne la corrélation intraclasse :

$$
\begin{pmatrix}
1 & \rho & \cdots & \rho \cr
\rho & 1 & \cdots & \rho \cr
\vdots & \vdots & \ddots & \vdots \cr
\rho & \rho & \cdots & 1
\end{pmatrix}
$$

Une structure plus libérale consiste à supposer que les corrélations intra-unités sont libres de varier d'une unité à l'autre, et sont donc non structurées (`uns`) :

$$
\begin{pmatrix}
1 & \rho_{1,2} & \cdots & \rho_{1,t} \cr
\rho_{1,2} & 1 & \cdots & \rho_{2,t} \cr
\vdots & \vdots & \ddots & \vdots \cr
\rho_{1,t} & \rho_{2,t} & \cdots & 1
\end{pmatrix}
$$

Enfin, il est également possible, surtout dans le cas des données temporelles, de considérer une structure de corrélation sérielle auto-régressive (`ar`) :

$$
\begin{pmatrix}
1 & \rho & \cdots & \rho^{t-1} \cr
\rho & 1 & \cdots & \rho^{t-2} \cr
\vdots & \vdots & \ddots & \vdots \cr
\rho^{t-1} & \rho^{t-2} & \cdots & 1
\end{pmatrix}
$$

Comment choisir une bonne matrice de corrélation de travail pour notre modèle GEE ? En règle générale, on testera le modèle avec deux matrices de corrélation (p.ex. `exch` et `uns`) pour vérifier si l'une des deux améliore sensiblement la qualité de l'ajustement ou si une structure particulière est bien en accord avec notre modèle de variance présupposé. Voici également quelques critères globaux permettant de choisir l'une ou l'autre des structures de corrélation possibles :

- non structurée : peu d'unités par cluster, dessin expérimental équilibré ;
- échangeable : les unités d'un même cluster n'ont pas d'ordre particulier ;
- auto-régressive : afin de rendre compte d'une réponse variant avec le temps ;
- indépendante : lorsque le nombre de clusters est faible.

Reste la question d'évaluer dans quelle mesure la matrice de corrélation retenue est appropriée, ce qui revient à formuler un test de spécification. La sensibilité à la mauvaise spécification de la matrice de corrélation se reflètera directement dans la précision des paramètres estimés, ou de manière équivalente au niveau de l'amplitude de leurs erreurs standard. Les estimateurs de variance peuvent de surcroît être de type "model-based" (pratique dans le cas d'un faible nombre de clusters, le cas échéant il est toujours possible d'utiliser un estimateur "jacknife") ou empiriques (on parle d'estimateurs "sandwich", et ils sont asymptotiquement sans bias). Mais on retiendra que même si la matrice de corrélation est mal spécifiée, le modèle GEE fournit des résultats valides sous réserve que l'estimateur de variance sandwich soit utilisé.

Voici une petite illustration sur des données tirées d'une étude sur l'effet de la pollution de l'air sur la capacité respiratoires chez 537 enfants agés de 7 à 10 ans. Le fait que la mère fume et le temps constituent les prédicteurs d'intérêt, et la variable réponse est la présence d'un symptôme asthmatique (respiration sifflante). Les données collectées sont résumées dans le tableau suivant :

![Tableau des résultats sur l'étude wheeziness](images/img_wheezing-status.png)

Le modèle considéré s'écrit :

$$ \text{logit}(\mu)=\beta_0+\beta_1\text{age}+\beta_2\text{smoke}+\beta_3\text{age}\times\text{smoke}, $$

et on parlera de "mean model" pour désigner un tel modèle dans lequel on s'intéresse à l'effet moyen (ici l'odds-ratio pour le status respiratoire) en fonction des prédicteurs, considérés à effets fixes dans ce modèle. Notons que ce modèle incorpore également un terme d'interaction ($\beta_3$).

Il est également nécessaire de spécifier la fonction variance. Dans ce cas précis, on choisira $\mathbb{V}(\mu)=\phi\mu\cdot(1-\mu)$, avec $\phi=1$ pour le paramètre d'échelle. On ne fait aucune hypothèse sur la distribution des observations.

Voici les données :

```{r}
library(geepack)
data(ohio)
head(ohio, n=8)
length(unique(ohio$id))
```

<figure>

```{r}
smoke.yes <- xtabs(resp ~ id + age, subset(ohio, smoke == 1))
smoke.no <- xtabs(resp ~ id + age, subset(ohio, smoke == 0
marg.means <- data.frame(resp = c(apply(smoke.yes, 2, mean), apply(smoke.no, 2, mean)),
                         age = gl(4, 1, labels = 7:10, ordered = TRUE),
                         smoke = gl(2, 4, labels = c("smoking", "not smoking")))
library(lattice)
library(latticeExtra)
p <- xyplot(resp ~ age, data = marg.means, group = smoke, type = c("l","g"),
            xlab = "Age (years)", ylab = "Wheeziness (%)", lwd = 2)
update(p, par.settings = custom.theme())
```

<figcaption>Fréquence des symptômes respiratoires en fonction du groupe d'âge et du status fumeur de la mère</figcaption>
</figure>

Et voici pour l'application numérique avec le package `geepack`{.pkg}. Le premier modèle que nous considérerons figure une matrice de corrélation de travail de type symétrique :

```{r}
fm <- resp ~ age*smoke
gee.fit <- geese(fm, id = id, data = ohio, family = binomial,
                 corstr = "exch", scale.fix = TRUE)
summary(gee.fit)
```

La corrélation intra-cluster est estimée à $\hat\rho=0.355$, et les résultats suggèrent que la fréquence des symptômes respiratoires diminue significativement ($p<0.001$), mais sans effet du statut fumeur de la mère. L'usage d'une matrice de corrélation non structurée amènerait aux même conclusions. En utilisant le package `gee`{.pkg}, qui repose sur un calcul de type "model-based" des erreurs standard, et une structure de corrélation indépedante, on se retrouverait à sous-estimer les paramètres de variance des effets stationnaires dans le temps :

```{r}
library(gee)
gee.fit.o <- gee(fm, id = id, data = ohio, family = binomial,
                 corstr = "independence", scale.fix = TRUE)
summary(gee.fit.o)$coefficients
```

Les matrices de variance-covariance robuste et naïve pour les paramètres du modèle sont stockées dans l'objet `gee.fit` et sont accessibles, respectivement, à l'aide de `gee.fit$vbeta` et `gee.fit$vbeta.naiv`. Ces deux matrices sont numériquement proches l'une de l'autre, à 3 décimales près :

```{r}
summary(as.vector(gee.fit$vbeta-gee.fit$vbeta.naiv))
```

Voici une autre syntaxe possible, en utilisant directement un estimateur sandwich :

```{r}
gee.fit.exch <- geeglm(fm, id = id, data = ohio, family = binomial,
                       corstr="exch", scale.fix = TRUE, std.err = "san.se")
summary(gee.fit.exch)
print(rob.se <- sqrt(diag(gee.fit.exch$geese$vbeta)))
```

On peut tester individuellement chaque facteur, par exemple le facteur `smoke`, à l'aide d'un test de Wald en comparant les deux modèles emboîtés grâce à la fonction `anova`{data-pkg="geepack"} :

```{r}
gee.fit.exch2 <- geeglm(update(fm, . ~ . - age), id = id, data = ohio, family = binomial,
                        corstr = "exch", scale.fix = TRUE, std.err = "san.se")
anova(gee.fit.exch, gee.fit.exch2)
```

Enfin, un intervalle de confiance à 95~\% peut être estimé comme suit :

```{r}
exp(coef(gee.fit.exch)["age"] + c(-1,1) * rob.se[2] * qnorm(0.975))
library(doBy)
gee.fit.ci <- esticon(gee.fit.exch, diag(4))
exp(gee.fit.ci[,c("Estimate","Lower","Upper")])
```

Le test $z$ de Wald est construit comme $\hat\beta_j/\text{SE}(\hat\beta_j)$ et suit une loi du chi-deux à un degré de liberté. On pourra vérifier qu'en utilisant $\text{SE}(\hat\beta_j)$ de la matrice de variance-covariance robuste (`rob.se` ci-dessus).

Finalement, on peut se demander quelle est la valeur estimée de l'odds-ratio ajusté pour l'âge, qui est significatif dans notre modèle initial. De même, quelle est la valeur de l'odds d'une réponse positive (respiration sifflante) chez des enfants de 8 ans _versus_ 10 ans lorsque la mère fume ou ne fume pas ?

Voici les réponses avec R :

```{r}
gee.fit2 <- geeglm(update(fm, . ~ . -age:smoke), id = id,
                   data = ohio, family = binomial,
                   corstr = "exch", scale.fix = TRUE)
exp(coef(gee.fit2)["age"])
gee.fit3 <- geeglm(resp ~ as.factor(age) + smoke, id = id,
                   data = ohio, family = binomial,
                   corstr = "exch", scale.fix = TRUE)
if (require(doBy)) esticon(gee.fit3, c(0, -1, 0, 1, 1))
exp(.Last.value$Estimate)
```

Enfin, voici un dernier exemple, avec calcul des valeurs (marginales) prédites par un modèle considérant une matrice de corrélation symétrique et un estimateur sandwich :

<figure>

```{r}
gee.fit.exch3 <- geeglm(update(fm, . ~ . - age:smoke), id = id, data = ohio, family = binomial,
                        corstr = "exch", scale.fix = TRUE, std.err = "san.se")
newdf <- expand.grid(age = seq(-2, 1, length = 50), smoke = c(0,1))
newdf <- cbind.data.frame(resp = predict(gee.fit.exch3, newdata = newdf), newdf)
p <- xyplot(exp(resp) ~ age, data = newdf, group = smoke, type = c("l","g"),
            xlab = "Age (years)", ylab = "Wheeziness (%)",
            auto.key = list(corner = c(0, 0), text = c("No", "Yes"), cex = .8))
update(p, par.settings = custom.theme())
```

<figcaption>Probabilités marginales prédites pour les deux groupes au cours du temps</figcaption>
</figure>

### Approche GLMM

On peut comparer les résultats précédents avec ceux que l'on obtiendrait _via_ une approche par modèle linéaire mixte. La syntaxe est la suivante :

```{r}
library(lme4)
fit.glmm <- lmer(resp ~ age + smoke + (1|id), data = ohio,
                 family = binomial)
fixef(fit.glmm)
head(fitted(fit.glmm))
```

On retrouve un effet significatif de l'âge, que l'on pourrait d'ailleurs confirmer à l'aide d'un test du rapport de vraisemblance (`anova(fit.glmm, update(fit.glmm, . ~ . - age))`), $\chi^2(1)=6.86$ with $p=0.009$.

Voici les mêmes paramètres estimés par les modèle GEE et GLMM :

```{r}
gee.fitc <- geeglm(resp ~ as.numeric(age) + smoke, id = id,
                   data = ohio, family = binomial,
                   corstr = "exch", scale.fix = TRUE)
glmm.fitc <- lmer(resp ~ as.numeric(age) + smoke + (1|id), data = ohio,
                  family = binomial)
exp(cbind(coef(gee.fitc), fixef(glmm.fitc)))
```

Quelle est la différence entre cette approche et la précédente ? Dans le cas du modèle mixte, on utilise une approche conditionnelle, d'où la nécessité de spécifier la distribution des effets aléatoires (dans ce cas précis, uniquement les intercepts individuels). Le modèle s'écrit :

$$ \text{logit}(\mu\mid\nu_i)=X\beta + \nu_i, $$

avec $\nu_i\sim N(0,\sigma_\nu^2)$ (les effets alatoires ont une moyenne nulle sur l'échelle de lien). En d'autres termes, au lieu de modéliser le log odds moyen de population, ce modèle à effet aléatoire permet de modéliser $\mu$ tout en tenant compte des variations inter-individuelles.

Les approches GEE et GLMM sont équivalentes uniquement dans le cas d'une fonction de lien identité (cas de la régression liénaire), bien que seule l'interprétation, voire le bien fondé, des coefficients du modèle change dans le cas d'autres fonctions de lien.
